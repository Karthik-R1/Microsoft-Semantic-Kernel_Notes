Following are the 'reasoning' frameworks used by AI Agents. (source: grok)


| **Framework**           | **Description**                                                                 | **How It Works**                                                                 | **Use Cases**                                                                 | **Strengths**                                                                 | **Limitations**                                                                 |
|-------------------------|---------------------------------------------------------------------------------|----------------------------------------------------------------------------------|-------------------------------------------------------------------------------|-------------------------------------------------------------------------------|---------------------------------------------------------------------------------|
| **Chain of Thought (CoT)** | Linear reasoning with explicit step-by-step articulation to reach a solution.   | Generates a sequence of steps, each building on the previous one.                 | Arithmetic, question answering, straightforward logical reasoning.            | Easy to implement, transparent, improves performance on sequential tasks.      | Limited to single path, may miss alternatives or fail on complex problems.       |
| **Tree of Thought (ToT)** | Hierarchical exploration of multiple reasoning paths organized as a tree.       | Generates and evaluates multiple hypotheses, expands promising branches, backtracks if needed. | Complex problem-solving, mathematical reasoning, strategic planning.          | Explores diverse solutions, handles ambiguity, robust for complex tasks.       | Computationally expensive, requires pruning to manage resources.                 |
| **Graph of Thought (GoT)** | Non-hierarchical reasoning with interconnected nodes forming a graph.           | Builds a network of reasoning steps, synthesizes insights across nodes.           | Creative tasks, interdisciplinary problem-solving, complex decision-making.   | Flexible, captures complex relationships, allows idea recombination.           | Highly computationally intensive, harder to implement.                          |
| **Self-Consistency**     | Generates multiple solutions and selects the most consistent or frequent one.   | Samples several reasoning paths, aggregates results (e.g., majority voting).      | Open-ended questions, ambiguous tasks, uncertainty handling.                  | Improves accuracy, reduces reliance on flawed paths.                          | Redundant for straightforward tasks, may not explore deeply divergent paths.    |
| **Prompt-Based Reasoning** | Reasoning based on zero-shot or few-shot prompts without explicit steps.        | Uses pre-trained knowledge and prompt structure to infer solutions.               | General-purpose tasks, quick answers, pattern recognition.                    | Fast, versatile, works with limited data.                                     | Lacks depth, may fail on complex tasks requiring structured reasoning.          |
| **Reflexion**            | Iterative self-evaluation and refinement of reasoning based on feedback.        | Generates a solution, critiques it, and revises in subsequent iterations.         | Code debugging, essay writing, complex problem-solving.                       | Mimics human self-correction, improves over time.                             | Requires effective self-evaluation mechanisms, challenging to implement.        |
| **Monte Carlo Tree Search (MCTS)** | Probabilistic tree-based search with random sampling to evaluate outcomes. | Builds a tree, simulates outcomes, selects path with best expected results.       | Game-playing, planning, optimization problems.                               | Balances exploration and exploitation, effective for sequential decisions.    | Computationally intensive, needs clear reward function.                         |
